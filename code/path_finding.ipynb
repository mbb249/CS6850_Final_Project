{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import json\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting graph preprocessing...\n",
      "Loading original features and edges...\n",
      "Loaded 37700 nodes with features.\n",
      "Loaded 289003 edges.\n",
      "Creating graph from edges...\n",
      "Graph created with 37700 nodes and 289003 edges.\n",
      "Identifying the largest connected component...\n",
      "Largest connected component has 37700 nodes and 289003 edges.\n",
      "Assigning features to nodes...\n",
      "Node features assigned.\n",
      "Standardizing features to fixed dimensions...\n",
      "Initial feature matrix shape: (37700, 4005)\n",
      "Reducing dimensions to 128 using PCA...\n"
     ]
    }
   ],
   "source": [
    "# Section 2: Preprocessing and Graph Construction\n",
    "\n",
    "# File paths\n",
    "original_features_path = \"../git_web_ml/musae_git_features.json\"\n",
    "original_edges_path = \"../git_web_ml/musae_git_edges.csv\"\n",
    "\n",
    "# Load data\n",
    "def load_data():\n",
    "    print(\"Loading original features and edges...\")\n",
    "    with open(original_features_path, \"r\") as f:\n",
    "        features = json.load(f)\n",
    "    print(f\"Loaded {len(features)} nodes with features.\")\n",
    "\n",
    "    edges = pd.read_csv(\n",
    "        original_edges_path, names=[\"source\", \"target\"], skiprows=1\n",
    "    )\n",
    "    print(f\"Loaded {len(edges)} edges.\")\n",
    "\n",
    "    # ML/Web developer targets\n",
    "    targets = pd.read_csv(\"../git_web_ml/musae_git_target.csv\")\n",
    "    target_dict = dict(zip(targets[\"id\"].astype(str), targets[\"ml_target\"]))\n",
    "    print(f\"Loaded {len(targets)} developer targets.\")\n",
    "\n",
    "    return features, edges, target_dict\n",
    "\n",
    "# Create graph and extract largest connected component\n",
    "def create_graph(features, edges, target_dict):\n",
    "    print(\"Creating graph from edges...\")\n",
    "    edges[\"source\"] = edges[\"source\"].astype(str)\n",
    "    edges[\"target\"] = edges[\"target\"].astype(str)\n",
    "    G = nx.from_pandas_edgelist(edges, source=\"source\", target=\"target\")\n",
    "    print(f\"Graph created with {len(G.nodes)} nodes and {len(G.edges)} edges.\")\n",
    "\n",
    "    print(\"Identifying the largest connected component...\")\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    G_lcc = G.subgraph(largest_cc).copy()\n",
    "    print(f\"Largest connected component has {len(G_lcc.nodes)} nodes and {len(G_lcc.edges)} edges.\")\n",
    "\n",
    "    print(\"Computing clustering coefficients\")\n",
    "    clustering_coeffs = nx.clustering(G_lcc)\n",
    "\n",
    "    print(\"Assigning features to nodes...\")\n",
    "    for node in G_lcc.nodes():\n",
    "        # Base features\n",
    "        if node in features:\n",
    "            G_lcc.nodes[node][\"features\"] = features[node]\n",
    "        else:\n",
    "            G_lcc.nodes[node][\"features\"] = []\n",
    "\n",
    "        additional_features = (\n",
    "            [\n",
    "                target_dict.get(node, -1),  # ML/Web developer target\n",
    "                G_lcc.degree(node),  # Degree\n",
    "                clustering_coeffs.get(node, 0),  # Clustering coefficient\n",
    "            ]\n",
    "        )\n",
    "    G_lcc.nodes[node][\"features\"].extend(additional_features)\n",
    "    print(\"Node features assigned.\")\n",
    "\n",
    "    return G_lcc\n",
    "\n",
    "# Standardize features using MultiLabelBinarizer and PCA\n",
    "def standardize_features(G, output_dim=128):\n",
    "    print(\"Standardizing features to fixed dimensions...\")\n",
    "    feature_list = [\n",
    "        set(feats) for feats in nx.get_node_attributes(G, \"features\").values()\n",
    "    ]\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    binary_features = mlb.fit_transform(feature_list)\n",
    "    print(f\"Initial feature matrix shape: {binary_features.shape}\")\n",
    "\n",
    "    if binary_features.shape[1] > output_dim:\n",
    "        print(f\"Reducing dimensions to {output_dim} using PCA...\")\n",
    "        pca = PCA(n_components=output_dim)\n",
    "        reduced_features = pca.fit_transform(binary_features)\n",
    "        print(f\"Feature matrix shape after PCA: {reduced_features.shape}\")\n",
    "    else:\n",
    "        print(f\"No dimensionality reduction needed. Retaining shape {binary_features.shape}\")\n",
    "        reduced_features = binary_features\n",
    "\n",
    "    print(\"Assigning standardized features back to nodes...\")\n",
    "    for idx, node in enumerate(G.nodes):\n",
    "        G.nodes[node][\"features\"] = reduced_features[idx]\n",
    "    print(\"Feature standardization complete.\")\n",
    "\n",
    "# Load, process, and standardize graph\n",
    "print(\"Starting graph preprocessing...\")\n",
    "features, edges, target_dict = load_data()\n",
    "G = create_graph(features, edges, target_dict)\n",
    "standardize_features(G, output_dim=128)\n",
    "print(f\"Graph preprocessing complete. Final graph has {len(G.nodes)} nodes and {len(G.edges)} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing BFS to ensure all nodes are connected...\n",
      "All nodes are connected. The graph is a single connected component.\n"
     ]
    }
   ],
   "source": [
    "def check_connectivity_bfs(G):\n",
    "    print(\"Performing BFS to ensure all nodes are connected...\")\n",
    "    start_node = next(iter(G.nodes))  # Get an arbitrary starting node\n",
    "    visited = set()\n",
    "    queue = [start_node]\n",
    "\n",
    "    while queue:\n",
    "        node = queue.pop(0)\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            queue.extend(neighbor for neighbor in G.neighbors(node) if neighbor not in visited)\n",
    "\n",
    "    if len(visited) == len(G.nodes):\n",
    "        print(\"All nodes are connected. The graph is a single connected component.\")\n",
    "    else:\n",
    "        print(f\"Graph is not fully connected. Only {len(visited)} out of {len(G.nodes)} nodes are reachable.\")\n",
    "\n",
    "\n",
    "check_connectivity_bfs(G)  # Ensure the graph is a single connected component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original features for node: [1574, 3773, 3571, 2672, 2478, 2534, 3129, 3077, 1171, 2045, 1539, 902, 1532, 2472, 1122, 2480, 3098, 2115, 1578]\n",
      "\n",
      "Transformed features (after PCA): [1574, 3773, 3571, 2672, 2478]\n"
     ]
    }
   ],
   "source": [
    "random_node = list(G.nodes())[0]\n",
    "with open(original_features_path, \"r\") as f:\n",
    "    original_features = json.load(f)\n",
    "print(\"Original features for node:\", original_features[random_node])\n",
    "\n",
    "# Then see how they're transformed\n",
    "print(\"\\nTransformed features (after PCA):\", G.nodes[random_node][\"features\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and splitting feature vectors...\n",
      "Creating feature vectors for ML tasks...\n",
      "Processing positive samples (existing edges)...\n",
      "Processed 0 positive samples.\n",
      "Processed 1000 positive samples.\n",
      "Processed 2000 positive samples.\n",
      "Processed 3000 positive samples.\n",
      "Processed 4000 positive samples.\n",
      "Processed 5000 positive samples.\n",
      "Processed 6000 positive samples.\n",
      "Processed 7000 positive samples.\n",
      "Processed 8000 positive samples.\n",
      "Processed 9000 positive samples.\n",
      "Processed 10000 positive samples.\n",
      "Processed 11000 positive samples.\n",
      "Processed 12000 positive samples.\n",
      "Processed 13000 positive samples.\n",
      "Processed 14000 positive samples.\n",
      "Processed 15000 positive samples.\n",
      "Processed 16000 positive samples.\n",
      "Processed 17000 positive samples.\n",
      "Processed 18000 positive samples.\n",
      "Processed 19000 positive samples.\n",
      "Processed 20000 positive samples.\n",
      "Processed 21000 positive samples.\n",
      "Processed 22000 positive samples.\n",
      "Processed 23000 positive samples.\n",
      "Processed 24000 positive samples.\n",
      "Processed 25000 positive samples.\n",
      "Processed 26000 positive samples.\n",
      "Processed 27000 positive samples.\n",
      "Processed 28000 positive samples.\n",
      "Processed 29000 positive samples.\n",
      "Processed 30000 positive samples.\n",
      "Processed 31000 positive samples.\n",
      "Processed 32000 positive samples.\n",
      "Processed 33000 positive samples.\n",
      "Processed 34000 positive samples.\n",
      "Processed 35000 positive samples.\n",
      "Processed 36000 positive samples.\n",
      "Processed 37000 positive samples.\n",
      "Processed 38000 positive samples.\n",
      "Processed 39000 positive samples.\n",
      "Processed 40000 positive samples.\n",
      "Processed 41000 positive samples.\n",
      "Processed 42000 positive samples.\n",
      "Processed 43000 positive samples.\n",
      "Processed 44000 positive samples.\n",
      "Processed 45000 positive samples.\n",
      "Processed 46000 positive samples.\n",
      "Processed 47000 positive samples.\n",
      "Processed 48000 positive samples.\n",
      "Processed 49000 positive samples.\n",
      "Processed 50000 positive samples.\n",
      "Processed 51000 positive samples.\n",
      "Processed 52000 positive samples.\n",
      "Processed 53000 positive samples.\n",
      "Processed 54000 positive samples.\n",
      "Processed 55000 positive samples.\n",
      "Processed 56000 positive samples.\n",
      "Processed 57000 positive samples.\n",
      "Processed 58000 positive samples.\n",
      "Processed 59000 positive samples.\n",
      "Processed 60000 positive samples.\n",
      "Processed 61000 positive samples.\n",
      "Processed 62000 positive samples.\n",
      "Processed 63000 positive samples.\n",
      "Processed 64000 positive samples.\n",
      "Processed 65000 positive samples.\n",
      "Processed 66000 positive samples.\n",
      "Processed 67000 positive samples.\n",
      "Processed 68000 positive samples.\n",
      "Processed 69000 positive samples.\n",
      "Processed 70000 positive samples.\n",
      "Processed 71000 positive samples.\n",
      "Processed 72000 positive samples.\n",
      "Processed 73000 positive samples.\n",
      "Processed 74000 positive samples.\n",
      "Processed 75000 positive samples.\n",
      "Processed 76000 positive samples.\n",
      "Processed 77000 positive samples.\n",
      "Processed 78000 positive samples.\n",
      "Processed 79000 positive samples.\n",
      "Processed 80000 positive samples.\n",
      "Processed 81000 positive samples.\n",
      "Processed 82000 positive samples.\n",
      "Processed 83000 positive samples.\n",
      "Processed 84000 positive samples.\n",
      "Processed 85000 positive samples.\n",
      "Processed 86000 positive samples.\n",
      "Processed 87000 positive samples.\n",
      "Processed 88000 positive samples.\n",
      "Processed 89000 positive samples.\n",
      "Processed 90000 positive samples.\n",
      "Processed 91000 positive samples.\n",
      "Processed 92000 positive samples.\n",
      "Processed 93000 positive samples.\n",
      "Processed 94000 positive samples.\n",
      "Processed 95000 positive samples.\n",
      "Processed 96000 positive samples.\n",
      "Processed 97000 positive samples.\n",
      "Processed 98000 positive samples.\n",
      "Processed 99000 positive samples.\n",
      "Processed 100000 positive samples.\n",
      "Processed 101000 positive samples.\n",
      "Processed 102000 positive samples.\n",
      "Processed 103000 positive samples.\n",
      "Processed 104000 positive samples.\n",
      "Processed 105000 positive samples.\n",
      "Processed 106000 positive samples.\n",
      "Processed 107000 positive samples.\n",
      "Processed 108000 positive samples.\n",
      "Processed 109000 positive samples.\n",
      "Processed 110000 positive samples.\n",
      "Processed 111000 positive samples.\n",
      "Processed 112000 positive samples.\n",
      "Processed 113000 positive samples.\n",
      "Processed 114000 positive samples.\n",
      "Processed 115000 positive samples.\n",
      "Processed 116000 positive samples.\n",
      "Processed 117000 positive samples.\n",
      "Processed 118000 positive samples.\n",
      "Processed 119000 positive samples.\n",
      "Processed 120000 positive samples.\n",
      "Processed 121000 positive samples.\n",
      "Processed 122000 positive samples.\n",
      "Processed 123000 positive samples.\n",
      "Processed 124000 positive samples.\n",
      "Processed 125000 positive samples.\n",
      "Processed 126000 positive samples.\n",
      "Processed 127000 positive samples.\n",
      "Processed 128000 positive samples.\n",
      "Processed 129000 positive samples.\n",
      "Processed 130000 positive samples.\n",
      "Processed 131000 positive samples.\n",
      "Processed 132000 positive samples.\n",
      "Processed 133000 positive samples.\n",
      "Processed 134000 positive samples.\n",
      "Processed 135000 positive samples.\n",
      "Processed 136000 positive samples.\n",
      "Processed 137000 positive samples.\n",
      "Processed 138000 positive samples.\n",
      "Processed 139000 positive samples.\n",
      "Processed 140000 positive samples.\n",
      "Processed 141000 positive samples.\n",
      "Processed 142000 positive samples.\n",
      "Processed 143000 positive samples.\n",
      "Processed 144000 positive samples.\n",
      "Processed 145000 positive samples.\n",
      "Processed 146000 positive samples.\n",
      "Processed 147000 positive samples.\n",
      "Processed 148000 positive samples.\n",
      "Processed 149000 positive samples.\n",
      "Processed 150000 positive samples.\n",
      "Processed 151000 positive samples.\n",
      "Processed 152000 positive samples.\n",
      "Processed 153000 positive samples.\n",
      "Processed 154000 positive samples.\n",
      "Processed 155000 positive samples.\n",
      "Processed 156000 positive samples.\n",
      "Processed 157000 positive samples.\n",
      "Processed 158000 positive samples.\n",
      "Processed 159000 positive samples.\n",
      "Processed 160000 positive samples.\n",
      "Processed 161000 positive samples.\n",
      "Processed 162000 positive samples.\n",
      "Processed 163000 positive samples.\n",
      "Processed 164000 positive samples.\n",
      "Processed 165000 positive samples.\n",
      "Processed 166000 positive samples.\n",
      "Processed 167000 positive samples.\n",
      "Processed 168000 positive samples.\n",
      "Processed 169000 positive samples.\n",
      "Processed 170000 positive samples.\n",
      "Processed 171000 positive samples.\n",
      "Processed 172000 positive samples.\n",
      "Processed 173000 positive samples.\n",
      "Processed 174000 positive samples.\n",
      "Processed 175000 positive samples.\n",
      "Processed 176000 positive samples.\n",
      "Processed 177000 positive samples.\n",
      "Processed 178000 positive samples.\n",
      "Processed 179000 positive samples.\n",
      "Processed 180000 positive samples.\n",
      "Processed 181000 positive samples.\n",
      "Processed 182000 positive samples.\n",
      "Processed 183000 positive samples.\n",
      "Processed 184000 positive samples.\n",
      "Processed 185000 positive samples.\n",
      "Processed 186000 positive samples.\n",
      "Processed 187000 positive samples.\n",
      "Processed 188000 positive samples.\n",
      "Processed 189000 positive samples.\n",
      "Processed 190000 positive samples.\n",
      "Processed 191000 positive samples.\n",
      "Processed 192000 positive samples.\n",
      "Processed 193000 positive samples.\n",
      "Processed 194000 positive samples.\n",
      "Processed 195000 positive samples.\n",
      "Processed 196000 positive samples.\n",
      "Processed 197000 positive samples.\n",
      "Processed 198000 positive samples.\n",
      "Processed 199000 positive samples.\n",
      "Processed 200000 positive samples.\n",
      "Processed 201000 positive samples.\n",
      "Processed 202000 positive samples.\n",
      "Processed 203000 positive samples.\n",
      "Processed 204000 positive samples.\n",
      "Processed 205000 positive samples.\n",
      "Processed 206000 positive samples.\n",
      "Processed 207000 positive samples.\n",
      "Processed 208000 positive samples.\n",
      "Processed 209000 positive samples.\n",
      "Processed 210000 positive samples.\n",
      "Processed 211000 positive samples.\n",
      "Processed 212000 positive samples.\n",
      "Processed 213000 positive samples.\n",
      "Processed 214000 positive samples.\n",
      "Processed 215000 positive samples.\n",
      "Processed 216000 positive samples.\n",
      "Processed 217000 positive samples.\n",
      "Processed 218000 positive samples.\n",
      "Processed 219000 positive samples.\n",
      "Processed 220000 positive samples.\n",
      "Processed 221000 positive samples.\n",
      "Processed 222000 positive samples.\n",
      "Processed 223000 positive samples.\n",
      "Processed 224000 positive samples.\n",
      "Processed 225000 positive samples.\n",
      "Processed 226000 positive samples.\n",
      "Processed 227000 positive samples.\n",
      "Processed 228000 positive samples.\n",
      "Processed 229000 positive samples.\n",
      "Processed 230000 positive samples.\n",
      "Processed 231000 positive samples.\n",
      "Processed 232000 positive samples.\n",
      "Processed 233000 positive samples.\n",
      "Processed 234000 positive samples.\n",
      "Processed 235000 positive samples.\n",
      "Processed 236000 positive samples.\n",
      "Processed 237000 positive samples.\n",
      "Processed 238000 positive samples.\n",
      "Processed 239000 positive samples.\n",
      "Processed 240000 positive samples.\n",
      "Processed 241000 positive samples.\n",
      "Processed 242000 positive samples.\n",
      "Processed 243000 positive samples.\n",
      "Processed 244000 positive samples.\n",
      "Processed 245000 positive samples.\n",
      "Processed 246000 positive samples.\n",
      "Processed 247000 positive samples.\n",
      "Processed 248000 positive samples.\n",
      "Processed 249000 positive samples.\n",
      "Processed 250000 positive samples.\n",
      "Processed 251000 positive samples.\n",
      "Processed 252000 positive samples.\n",
      "Processed 253000 positive samples.\n",
      "Processed 254000 positive samples.\n",
      "Processed 255000 positive samples.\n",
      "Processed 256000 positive samples.\n",
      "Processed 257000 positive samples.\n",
      "Processed 258000 positive samples.\n",
      "Processed 259000 positive samples.\n",
      "Processed 260000 positive samples.\n",
      "Processed 261000 positive samples.\n",
      "Processed 262000 positive samples.\n",
      "Processed 263000 positive samples.\n",
      "Processed 264000 positive samples.\n",
      "Processed 265000 positive samples.\n",
      "Processed 266000 positive samples.\n",
      "Processed 267000 positive samples.\n",
      "Processed 268000 positive samples.\n",
      "Processed 269000 positive samples.\n",
      "Processed 270000 positive samples.\n",
      "Processed 271000 positive samples.\n",
      "Processed 272000 positive samples.\n",
      "Processed 273000 positive samples.\n",
      "Processed 274000 positive samples.\n",
      "Processed 275000 positive samples.\n",
      "Processed 276000 positive samples.\n",
      "Processed 277000 positive samples.\n",
      "Processed 278000 positive samples.\n",
      "Processed 279000 positive samples.\n",
      "Processed 280000 positive samples.\n",
      "Processed 281000 positive samples.\n",
      "Processed 282000 positive samples.\n",
      "Processed 283000 positive samples.\n",
      "Processed 284000 positive samples.\n",
      "Processed 285000 positive samples.\n",
      "Processed 286000 positive samples.\n",
      "Processed 287000 positive samples.\n",
      "Processed 288000 positive samples.\n",
      "Processed 289000 positive samples.\n",
      "Generating negative samples (random non-existing edges)...\n",
      "Generated 0 negative samples.\n",
      "Generated 1000 negative samples.\n",
      "Generated 2000 negative samples.\n",
      "Generated 3000 negative samples.\n",
      "Generated 4000 negative samples.\n",
      "Generated 5000 negative samples.\n",
      "Generated 6000 negative samples.\n",
      "Generated 7000 negative samples.\n",
      "Generated 8000 negative samples.\n",
      "Generated 9000 negative samples.\n",
      "Generated 10000 negative samples.\n",
      "Generated 11000 negative samples.\n",
      "Generated 12000 negative samples.\n",
      "Generated 13000 negative samples.\n",
      "Generated 14000 negative samples.\n",
      "Generated 15000 negative samples.\n",
      "Generated 16000 negative samples.\n",
      "Generated 17000 negative samples.\n",
      "Generated 18000 negative samples.\n",
      "Generated 19000 negative samples.\n",
      "Generated 20000 negative samples.\n",
      "Generated 21000 negative samples.\n",
      "Generated 22000 negative samples.\n",
      "Generated 23000 negative samples.\n",
      "Generated 24000 negative samples.\n",
      "Generated 25000 negative samples.\n",
      "Generated 26000 negative samples.\n",
      "Generated 27000 negative samples.\n",
      "Generated 28000 negative samples.\n",
      "Generated 29000 negative samples.\n",
      "Generated 30000 negative samples.\n",
      "Generated 31000 negative samples.\n",
      "Generated 32000 negative samples.\n",
      "Generated 33000 negative samples.\n",
      "Generated 34000 negative samples.\n",
      "Generated 35000 negative samples.\n",
      "Generated 36000 negative samples.\n",
      "Generated 37000 negative samples.\n",
      "Generated 38000 negative samples.\n",
      "Generated 39000 negative samples.\n",
      "Generated 40000 negative samples.\n",
      "Generated 41000 negative samples.\n",
      "Generated 42000 negative samples.\n",
      "Generated 43000 negative samples.\n",
      "Generated 44000 negative samples.\n",
      "Generated 45000 negative samples.\n",
      "Generated 46000 negative samples.\n",
      "Generated 47000 negative samples.\n",
      "Generated 48000 negative samples.\n",
      "Generated 49000 negative samples.\n",
      "Generated 50000 negative samples.\n",
      "Generated 51000 negative samples.\n",
      "Generated 52000 negative samples.\n",
      "Generated 53000 negative samples.\n",
      "Generated 54000 negative samples.\n",
      "Generated 55000 negative samples.\n",
      "Generated 56000 negative samples.\n",
      "Generated 57000 negative samples.\n",
      "Generated 58000 negative samples.\n",
      "Generated 59000 negative samples.\n",
      "Generated 60000 negative samples.\n",
      "Generated 61000 negative samples.\n",
      "Generated 62000 negative samples.\n",
      "Generated 63000 negative samples.\n",
      "Generated 64000 negative samples.\n",
      "Generated 65000 negative samples.\n",
      "Generated 66000 negative samples.\n",
      "Generated 67000 negative samples.\n",
      "Generated 68000 negative samples.\n",
      "Generated 69000 negative samples.\n",
      "Generated 70000 negative samples.\n",
      "Generated 71000 negative samples.\n",
      "Generated 72000 negative samples.\n",
      "Generated 73000 negative samples.\n",
      "Generated 74000 negative samples.\n",
      "Generated 75000 negative samples.\n",
      "Generated 76000 negative samples.\n",
      "Generated 77000 negative samples.\n",
      "Generated 78000 negative samples.\n",
      "Generated 79000 negative samples.\n",
      "Generated 80000 negative samples.\n",
      "Generated 81000 negative samples.\n",
      "Generated 82000 negative samples.\n",
      "Generated 83000 negative samples.\n",
      "Generated 84000 negative samples.\n",
      "Generated 85000 negative samples.\n",
      "Generated 86000 negative samples.\n",
      "Generated 87000 negative samples.\n",
      "Generated 88000 negative samples.\n",
      "Generated 89000 negative samples.\n",
      "Generated 90000 negative samples.\n",
      "Generated 91000 negative samples.\n",
      "Generated 92000 negative samples.\n",
      "Generated 93000 negative samples.\n",
      "Generated 94000 negative samples.\n",
      "Generated 95000 negative samples.\n",
      "Generated 96000 negative samples.\n",
      "Generated 97000 negative samples.\n",
      "Generated 98000 negative samples.\n",
      "Generated 99000 negative samples.\n",
      "Generated 100000 negative samples.\n",
      "Generated 101000 negative samples.\n",
      "Generated 102000 negative samples.\n",
      "Generated 103000 negative samples.\n",
      "Generated 104000 negative samples.\n",
      "Generated 105000 negative samples.\n",
      "Generated 106000 negative samples.\n",
      "Generated 107000 negative samples.\n",
      "Generated 108000 negative samples.\n",
      "Generated 109000 negative samples.\n",
      "Generated 110000 negative samples.\n",
      "Generated 111000 negative samples.\n",
      "Generated 112000 negative samples.\n",
      "Generated 113000 negative samples.\n",
      "Generated 114000 negative samples.\n",
      "Generated 115000 negative samples.\n",
      "Generated 116000 negative samples.\n",
      "Generated 117000 negative samples.\n",
      "Generated 118000 negative samples.\n",
      "Generated 119000 negative samples.\n",
      "Generated 120000 negative samples.\n",
      "Generated 121000 negative samples.\n",
      "Generated 122000 negative samples.\n",
      "Generated 123000 negative samples.\n",
      "Generated 124000 negative samples.\n",
      "Generated 125000 negative samples.\n",
      "Generated 126000 negative samples.\n",
      "Generated 127000 negative samples.\n",
      "Generated 128000 negative samples.\n",
      "Generated 129000 negative samples.\n",
      "Generated 130000 negative samples.\n",
      "Generated 131000 negative samples.\n",
      "Generated 132000 negative samples.\n",
      "Generated 133000 negative samples.\n",
      "Generated 134000 negative samples.\n",
      "Generated 135000 negative samples.\n",
      "Generated 136000 negative samples.\n",
      "Generated 137000 negative samples.\n",
      "Generated 138000 negative samples.\n",
      "Generated 139000 negative samples.\n",
      "Generated 140000 negative samples.\n",
      "Generated 141000 negative samples.\n",
      "Generated 142000 negative samples.\n",
      "Generated 143000 negative samples.\n",
      "Generated 144000 negative samples.\n",
      "Generated 145000 negative samples.\n",
      "Generated 146000 negative samples.\n",
      "Generated 147000 negative samples.\n",
      "Generated 148000 negative samples.\n",
      "Generated 149000 negative samples.\n",
      "Generated 150000 negative samples.\n",
      "Generated 151000 negative samples.\n",
      "Generated 152000 negative samples.\n",
      "Generated 153000 negative samples.\n",
      "Generated 154000 negative samples.\n",
      "Generated 155000 negative samples.\n",
      "Generated 156000 negative samples.\n",
      "Generated 157000 negative samples.\n",
      "Generated 158000 negative samples.\n",
      "Generated 159000 negative samples.\n",
      "Generated 160000 negative samples.\n",
      "Generated 161000 negative samples.\n",
      "Generated 162000 negative samples.\n",
      "Generated 163000 negative samples.\n",
      "Generated 164000 negative samples.\n",
      "Generated 165000 negative samples.\n",
      "Generated 166000 negative samples.\n",
      "Generated 167000 negative samples.\n",
      "Generated 168000 negative samples.\n",
      "Generated 169000 negative samples.\n",
      "Generated 170000 negative samples.\n",
      "Generated 171000 negative samples.\n",
      "Generated 172000 negative samples.\n",
      "Generated 173000 negative samples.\n",
      "Generated 174000 negative samples.\n",
      "Generated 175000 negative samples.\n",
      "Generated 176000 negative samples.\n",
      "Generated 177000 negative samples.\n",
      "Generated 178000 negative samples.\n",
      "Generated 179000 negative samples.\n",
      "Generated 180000 negative samples.\n",
      "Generated 181000 negative samples.\n",
      "Generated 182000 negative samples.\n",
      "Generated 183000 negative samples.\n",
      "Generated 184000 negative samples.\n",
      "Generated 185000 negative samples.\n",
      "Generated 186000 negative samples.\n",
      "Generated 187000 negative samples.\n",
      "Generated 188000 negative samples.\n",
      "Generated 189000 negative samples.\n",
      "Generated 190000 negative samples.\n",
      "Generated 191000 negative samples.\n",
      "Generated 192000 negative samples.\n",
      "Generated 193000 negative samples.\n",
      "Generated 194000 negative samples.\n",
      "Generated 195000 negative samples.\n",
      "Generated 196000 negative samples.\n",
      "Generated 197000 negative samples.\n",
      "Generated 198000 negative samples.\n",
      "Generated 199000 negative samples.\n",
      "Generated 200000 negative samples.\n",
      "Generated 201000 negative samples.\n",
      "Generated 202000 negative samples.\n",
      "Generated 203000 negative samples.\n",
      "Generated 204000 negative samples.\n",
      "Generated 205000 negative samples.\n",
      "Generated 206000 negative samples.\n",
      "Generated 207000 negative samples.\n",
      "Generated 208000 negative samples.\n",
      "Generated 209000 negative samples.\n",
      "Generated 210000 negative samples.\n",
      "Generated 211000 negative samples.\n",
      "Generated 212000 negative samples.\n",
      "Generated 213000 negative samples.\n",
      "Generated 214000 negative samples.\n",
      "Generated 215000 negative samples.\n",
      "Generated 216000 negative samples.\n",
      "Generated 217000 negative samples.\n",
      "Generated 218000 negative samples.\n",
      "Generated 219000 negative samples.\n",
      "Generated 220000 negative samples.\n",
      "Generated 221000 negative samples.\n",
      "Generated 222000 negative samples.\n",
      "Generated 223000 negative samples.\n",
      "Generated 224000 negative samples.\n",
      "Generated 225000 negative samples.\n",
      "Generated 226000 negative samples.\n",
      "Generated 227000 negative samples.\n",
      "Generated 228000 negative samples.\n",
      "Generated 229000 negative samples.\n",
      "Generated 230000 negative samples.\n",
      "Generated 231000 negative samples.\n",
      "Generated 232000 negative samples.\n",
      "Generated 233000 negative samples.\n",
      "Generated 234000 negative samples.\n",
      "Generated 235000 negative samples.\n",
      "Generated 236000 negative samples.\n",
      "Generated 237000 negative samples.\n",
      "Generated 238000 negative samples.\n",
      "Generated 239000 negative samples.\n",
      "Generated 240000 negative samples.\n",
      "Generated 241000 negative samples.\n",
      "Generated 242000 negative samples.\n",
      "Generated 243000 negative samples.\n",
      "Generated 244000 negative samples.\n",
      "Generated 245000 negative samples.\n",
      "Generated 246000 negative samples.\n",
      "Generated 247000 negative samples.\n",
      "Generated 248000 negative samples.\n",
      "Generated 249000 negative samples.\n",
      "Generated 250000 negative samples.\n",
      "Generated 251000 negative samples.\n",
      "Generated 252000 negative samples.\n",
      "Generated 253000 negative samples.\n",
      "Generated 254000 negative samples.\n",
      "Generated 255000 negative samples.\n",
      "Generated 256000 negative samples.\n",
      "Generated 257000 negative samples.\n",
      "Generated 258000 negative samples.\n",
      "Generated 259000 negative samples.\n",
      "Generated 260000 negative samples.\n",
      "Generated 261000 negative samples.\n",
      "Generated 262000 negative samples.\n",
      "Generated 263000 negative samples.\n",
      "Generated 264000 negative samples.\n",
      "Generated 265000 negative samples.\n",
      "Generated 266000 negative samples.\n",
      "Generated 267000 negative samples.\n",
      "Generated 268000 negative samples.\n",
      "Generated 269000 negative samples.\n",
      "Generated 270000 negative samples.\n",
      "Generated 271000 negative samples.\n",
      "Generated 272000 negative samples.\n",
      "Generated 273000 negative samples.\n",
      "Generated 274000 negative samples.\n",
      "Generated 275000 negative samples.\n",
      "Generated 276000 negative samples.\n",
      "Generated 277000 negative samples.\n",
      "Generated 278000 negative samples.\n",
      "Generated 279000 negative samples.\n",
      "Generated 280000 negative samples.\n",
      "Generated 281000 negative samples.\n",
      "Generated 282000 negative samples.\n",
      "Generated 283000 negative samples.\n",
      "Generated 284000 negative samples.\n",
      "Generated 285000 negative samples.\n",
      "Generated 286000 negative samples.\n",
      "Generated 287000 negative samples.\n",
      "Generated 288000 negative samples.\n",
      "Generated 289000 negative samples.\n",
      "Feature vectors created. Total samples: 577879\n",
      "Training set size: 462303, Test set size: 115576\n",
      "Feature vectors and splits saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Section 3A: Create Feature Vectors\n",
    "\n",
    "def create_feature_vectors(G, edges):\n",
    "    print(\"Creating feature vectors for ML tasks...\")\n",
    "    X, y = [], []\n",
    "\n",
    "    print(\"Processing positive samples (existing edges)...\")\n",
    "    for i, (_, row) in enumerate(edges.iterrows()):\n",
    "        node1, node2 = str(row[\"source\"]), str(row[\"target\"])\n",
    "        if node1 in G.nodes and node2 in G.nodes:\n",
    "            feature_vector = np.array(G.nodes[node1][\"features\"]) - np.array(G.nodes[node2][\"features\"])\n",
    "            X.append(feature_vector)\n",
    "            y.append(1)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Processed {i} positive samples.\")\n",
    "\n",
    "    print(\"Generating negative samples (random non-existing edges)...\")\n",
    "    all_nodes = list(G.nodes)\n",
    "    for i in range(len(edges)):\n",
    "        node1, node2 = np.random.choice(all_nodes, 2, replace=False)\n",
    "        if not G.has_edge(node1, node2):\n",
    "            feature_vector = np.array(G.nodes[node1][\"features\"]) - np.array(G.nodes[node2][\"features\"])\n",
    "            X.append(feature_vector)\n",
    "            y.append(0)\n",
    "        if i % 1000 == 0:\n",
    "            print(f\"Generated {i} negative samples.\")\n",
    "\n",
    "    print(f\"Feature vectors created. Total samples: {len(X)}\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create and split feature vectors\n",
    "print(\"Creating and splitting feature vectors...\")\n",
    "X, y = create_feature_vectors(G, edges)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")\n",
    "\n",
    "with open(\"feature_vectors.pkl\", \"wb\") as f:\n",
    "    pickle.dump((X, y, X_train, X_test, y_train, y_test), f)\n",
    "\n",
    "print(\"Feature vectors and splits saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vectors and splits loaded successfully.\n",
      "Training set size: 462303, Test set size: 115576\n"
     ]
    }
   ],
   "source": [
    "with open(\"feature_vectors.pkl\", \"rb\") as f:\n",
    "    X, y, X_train, X_test, y_train, y_test = pickle.load(f)\n",
    "\n",
    "print(\"Feature vectors and splits loaded successfully.\")\n",
    "print(f\"Training set size: {X_train.shape[0]}, Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defining the neural network model...\n",
      "Model defined successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milesbramwit/cs6850/Final_Project/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Hidden_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Hidden_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Hidden_Layer_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Hidden_Layer_2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,881</span> (105.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,881\u001b[0m (105.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,881</span> (105.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,881\u001b[0m (105.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling the model...\n",
      "Model compiled successfully.\n",
      "Starting model training...\n",
      "\n",
      "Epoch 1:\n",
      "  Training Loss: 0.3206, Training Accuracy: 0.8582\n",
      "  Validation Loss: 0.2825, Validation Accuracy: 0.8786\n",
      "\n",
      "Epoch 2:\n",
      "  Training Loss: 0.2741, Training Accuracy: 0.8815\n",
      "  Validation Loss: 0.2704, Validation Accuracy: 0.8836\n",
      "\n",
      "Epoch 3:\n",
      "  Training Loss: 0.2588, Training Accuracy: 0.8879\n",
      "  Validation Loss: 0.2629, Validation Accuracy: 0.8870\n",
      "\n",
      "Epoch 4:\n",
      "  Training Loss: 0.2497, Training Accuracy: 0.8917\n",
      "  Validation Loss: 0.2590, Validation Accuracy: 0.8892\n",
      "\n",
      "Epoch 5:\n",
      "  Training Loss: 0.2427, Training Accuracy: 0.8948\n",
      "  Validation Loss: 0.2591, Validation Accuracy: 0.8887\n",
      "\n",
      "Epoch 6:\n",
      "  Training Loss: 0.2374, Training Accuracy: 0.8972\n",
      "  Validation Loss: 0.2573, Validation Accuracy: 0.8904\n",
      "\n",
      "Epoch 7:\n",
      "  Training Loss: 0.2329, Training Accuracy: 0.8991\n",
      "  Validation Loss: 0.2572, Validation Accuracy: 0.8906\n",
      "\n",
      "Epoch 8:\n",
      "  Training Loss: 0.2288, Training Accuracy: 0.9011\n",
      "  Validation Loss: 0.2586, Validation Accuracy: 0.8894\n",
      "\n",
      "Epoch 9:\n",
      "  Training Loss: 0.2250, Training Accuracy: 0.9022\n",
      "  Validation Loss: 0.2603, Validation Accuracy: 0.8900\n",
      "\n",
      "Epoch 10:\n",
      "  Training Loss: 0.2217, Training Accuracy: 0.9038\n",
      "  Validation Loss: 0.2573, Validation Accuracy: 0.8900\n",
      "\n",
      "Epoch 11:\n",
      "  Training Loss: 0.2188, Training Accuracy: 0.9052\n",
      "  Validation Loss: 0.2618, Validation Accuracy: 0.8906\n",
      "\n",
      "Epoch 12:\n",
      "  Training Loss: 0.2162, Training Accuracy: 0.9062\n",
      "  Validation Loss: 0.2663, Validation Accuracy: 0.8892\n",
      "\n",
      "Epoch 13:\n",
      "  Training Loss: 0.2136, Training Accuracy: 0.9074\n",
      "  Validation Loss: 0.2661, Validation Accuracy: 0.8889\n",
      "\n",
      "Epoch 14:\n",
      "  Training Loss: 0.2114, Training Accuracy: 0.9085\n",
      "  Validation Loss: 0.2637, Validation Accuracy: 0.8887\n",
      "\n",
      "Epoch 15:\n",
      "  Training Loss: 0.2093, Training Accuracy: 0.9096\n",
      "  Validation Loss: 0.2690, Validation Accuracy: 0.8881\n",
      "\n",
      "Epoch 16:\n",
      "  Training Loss: 0.2070, Training Accuracy: 0.9106\n",
      "  Validation Loss: 0.2723, Validation Accuracy: 0.8876\n",
      "\n",
      "Epoch 17:\n",
      "  Training Loss: 0.2051, Training Accuracy: 0.9115\n",
      "  Validation Loss: 0.2712, Validation Accuracy: 0.8865\n",
      "\n",
      "Epoch 18:\n",
      "  Training Loss: 0.2035, Training Accuracy: 0.9123\n",
      "  Validation Loss: 0.2807, Validation Accuracy: 0.8872\n",
      "\n",
      "Epoch 19:\n",
      "  Training Loss: 0.2014, Training Accuracy: 0.9132\n",
      "  Validation Loss: 0.2760, Validation Accuracy: 0.8855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 20:\n",
      "  Training Loss: 0.2000, Training Accuracy: 0.9137\n",
      "  Validation Loss: 0.2774, Validation Accuracy: 0.8865\n",
      "Model training complete.\n",
      "Model saved successfully to 'trained_model.h5'.\n",
      "Training history saved successfully to 'training_history.pkl'.\n",
      "Evaluating the model on the test set...\n",
      "\u001b[1m3612/3612\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 499us/step - accuracy: 0.8873 - loss: 0.2788\n",
      "Test Loss: 0.2810\n",
      "Test Accuracy: 0.8864\n"
     ]
    }
   ],
   "source": [
    "# Section 3B: Train the Neural Network\n",
    "\n",
    "# Define the neural network\n",
    "print(\"Defining the neural network model...\")\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation=\"relu\", input_shape=(X_train.shape[1],), name=\"Input_Layer\"),\n",
    "    tf.keras.layers.Dense(64, activation=\"relu\", name=\"Hidden_Layer_1\"),\n",
    "    tf.keras.layers.Dense(32, activation=\"relu\", name=\"Hidden_Layer_2\"),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"Output_Layer\"),\n",
    "])\n",
    "print(\"Model defined successfully.\")\n",
    "model.summary()\n",
    "\n",
    "# Compile the model\n",
    "print(\"Compiling the model...\")\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "print(\"Model compiled successfully.\")\n",
    "\n",
    "# Define a custom callback for logging\n",
    "class TrainingLogger(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        print(f\"\\nEpoch {epoch + 1}:\")\n",
    "        print(\n",
    "            f\"  Training Loss: {logs['loss']:.4f}, Training Accuracy: {logs['accuracy']:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"  Validation Loss: {logs['val_loss']:.4f}, Validation Accuracy: {logs['val_accuracy']:.4f}\"\n",
    "        )\n",
    "\n",
    "# Train the model\n",
    "print(\"Starting model training...\")\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[TrainingLogger()],\n",
    "    verbose=0  # Suppress default verbose to use custom logging\n",
    ")\n",
    "print(\"Model training complete.\")\n",
    "\n",
    "# Evaluate the model\n",
    "model.save(\"trained_model.h5\")\n",
    "print(\"Model saved successfully to 'trained_model.h5'.\")\n",
    "\n",
    "# Save the training history\n",
    "with open(\"training_history.pkl\", \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "print(\"Training history saved successfully to 'training_history.pkl'.\")\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Evaluating the model on the test set...\")\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from 'trained_model.h5'.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Hidden_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Hidden_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ Input_Layer (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m16,512\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Hidden_Layer_1 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Hidden_Layer_2 (\u001b[38;5;33mDense\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,883</span> (105.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m26,883\u001b[0m (105.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">26,881</span> (105.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m26,881\u001b[0m (105.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training history loaded successfully from 'training_history.pkl'.\n",
      "Loaded Training History:\n",
      "accuracy: [0.8582178354263306, 0.8815007209777832, 0.8878872394561768, 0.8916618227958679, 0.8948037028312683]...\n",
      "loss: [0.32061806321144104, 0.2741466164588928, 0.2588496506214142, 0.2497376650571823, 0.2426992654800415]...\n",
      "val_accuracy: [0.8786190748214722, 0.8836482167243958, 0.8870442509651184, 0.8892289996147156, 0.8887098431587219]...\n",
      "val_loss: [0.28252294659614563, 0.2703949809074402, 0.26289796829223633, 0.25896233320236206, 0.2591072916984558]...\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = tf.keras.models.load_model(\"trained_model.h5\")\n",
    "print(\"Model loaded successfully from 'trained_model.h5'.\")\n",
    "model.summary()\n",
    "\n",
    "# Load the training history\n",
    "with open(\"training_history.pkl\", \"rb\") as f:\n",
    "    history = pickle.load(f)\n",
    "print(\"Training history loaded successfully from 'training_history.pkl'.\")\n",
    "\n",
    "# Print the loaded training history (optional)\n",
    "print(\"Loaded Training History:\")\n",
    "for key, values in history.items():\n",
    "    print(f\"{key}: {values[:5]}...\")  # Show first 5 values as a preview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_node_ml(model, G, current_node, target_node, visited, prediction_cache, debug=False):\n",
    "    if debug:\n",
    "        print(f\"Predicting next node from current node: {current_node}, target: {target_node}\")\n",
    "\n",
    "    neighbors = [n for n in G.neighbors(current_node) if n not in visited]\n",
    "\n",
    "    if not neighbors:\n",
    "        if debug:\n",
    "            print(\"No unvisited neighbors available.\")\n",
    "        return None  # No unvisited neighbors\n",
    "\n",
    "    # Check if the target node is one of the neighbors\n",
    "    if target_node in neighbors:\n",
    "        if debug:\n",
    "            print(f\"Target node {target_node} is a direct neighbor of {current_node}. Auto-selecting target.\")\n",
    "        return target_node  # Auto-select the target node\n",
    "\n",
    "    # Cache predictions to avoid redundant computations\n",
    "    if current_node not in prediction_cache:\n",
    "        target_features = G.nodes[target_node][\"features\"]\n",
    "        predictions = []\n",
    "        for neighbor in neighbors:\n",
    "            neighbor_features = G.nodes[neighbor][\"features\"]\n",
    "            feature_vector = neighbor_features - target_features\n",
    "            prob = model.predict(feature_vector.reshape(1, -1), verbose=0)[0][0]  # Suppress model output\n",
    "            predictions.append((neighbor, prob))\n",
    "            if debug:\n",
    "                print(f\"Prediction for neighbor {neighbor}: {prob:.4f}\")\n",
    "        predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "        prediction_cache[current_node] = predictions\n",
    "    else:\n",
    "        if debug:\n",
    "            print(f\"Using cached predictions for {current_node}\")\n",
    "        predictions = prediction_cache[current_node]\n",
    "\n",
    "    # Select the next node based on predictions\n",
    "    for neighbor, prob in predictions:\n",
    "        if neighbor not in visited:\n",
    "            if debug:\n",
    "                print(f\"Next node selected: {neighbor} with probability {prob:.4f}\")\n",
    "            return neighbor\n",
    "\n",
    "    if debug:\n",
    "        print(\"No valid next node found.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def predict_next_node_degree(\n",
    "    G, current_node, target_node, visited, prediction_cache, debug=False\n",
    "):\n",
    "    \"\"\"Degree-based prediction - selects neighbor with highest degree.\"\"\"\n",
    "    # TODO: Implement degree-based routing strategy\n",
    "    pass\n",
    "\n",
    "ROUTING_STRATEGIES = {\n",
    "    \"ml\": predict_next_node_ml,\n",
    "    \"degree\": predict_next_node_degree,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the path with a limit on the number of hops\n",
    "def find_path(G, source, target, strategy=\"degree\", max_hops=40, model=None, debug=False):\n",
    "    if debug:\n",
    "        print(\n",
    "            f\"Starting pathfinding from source: {source} to target: {target}, with max hops: {max_hops}\"\n",
    "        )\n",
    "    if (model==None and strategy==\"ml\"):\n",
    "        raise Exception(\"Need a model if using ML strategy\")\n",
    "    predict_next_node = ROUTING_STRATEGIES[strategy]\n",
    "    current_node = source\n",
    "    visited = set()\n",
    "    prediction_cache = {}  # Cache predictions to avoid recomputation\n",
    "    path = [source]\n",
    "    hops = 0\n",
    "\n",
    "    while current_node != target:\n",
    "        print(f\"Current Number of Hops: {hops}\")\n",
    "        print(f\"Current Node: {current_node}\")\n",
    "        visited.add(current_node)\n",
    "        if (strategy == \"ml\"):\n",
    "            next_node = predict_next_node(\n",
    "              model, G, current_node, target, visited, prediction_cache, debug=debug\n",
    "          )\n",
    "        else:\n",
    "            next_node = predict_next_node(\n",
    "                G, current_node, target, visited, prediction_cache, debug=debug\n",
    "            )\n",
    "        if next_node is None:\n",
    "            if debug:\n",
    "                print(f\"Pathfinding failed: no valid neighbors from {current_node}.\")\n",
    "            return None  # No path found\n",
    "        path.append(next_node)\n",
    "        current_node = next_node\n",
    "        hops += 1\n",
    "\n",
    "        if hops > max_hops:\n",
    "            if debug:\n",
    "                print(f\"Pathfinding terminated: exceeded max hops ({max_hops}).\")\n",
    "            return None\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Pathfinding complete. Path: {path}\")\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/20: Source 29917 -> Target 28503\n",
      "Current Number of Hops: (0).\n",
      "Current Number of Hops: (1).\n",
      "Current Number of Hops: (2).\n"
     ]
    }
   ],
   "source": [
    "# Evaluate pathfinding with paths included in the output\n",
    "def evaluate_pathfinding(\n",
    "    G, model = None, strategy=\"degree\", max_hops=20, num_runs=20, seed=42, debug=False\n",
    "):\n",
    "    random.seed(seed)\n",
    "    total_hops = 0\n",
    "    successful_runs = 0\n",
    "\n",
    "    node_list = list(G.nodes)\n",
    "    all_pairs = []\n",
    "    for _ in range(num_runs):\n",
    "        source, target = random.sample(node_list, 2)\n",
    "        all_pairs.append((source, target))\n",
    "\n",
    "    results = []\n",
    "    for run, (source_node, target_node) in enumerate(all_pairs):\n",
    "        print(f\"Run {run + 1}/{num_runs}: Source {source_node} -> Target {target_node}\")\n",
    "\n",
    "        path = find_path(G, source_node, target_node, strategy, max_hops, model, debug)\n",
    "\n",
    "        if path:\n",
    "            num_hops = len(path) - 1\n",
    "            print(f\"  Path found in {num_hops} hops. Path: {path}\")\n",
    "            total_hops += num_hops\n",
    "            successful_runs += 1\n",
    "            results.append(\n",
    "                {\"run\": run + 1, \"success\": True, \"hops\": num_hops, \"path\": path}\n",
    "            )\n",
    "        else:\n",
    "            print(\"  No path found or run terminated.\")\n",
    "            results.append(\n",
    "                {\"run\": run + 1, \"success\": False, \"hops\": None, \"path\": None}\n",
    "            )\n",
    "\n",
    "    success_rate = (successful_runs / num_runs) * 100\n",
    "    average_hops = total_hops / successful_runs if successful_runs > 0 else float(\"inf\")\n",
    "\n",
    "    print(f\"\\n--- Summary ---\")\n",
    "    print(f\"Success rate: {success_rate:.2f}% ({successful_runs}/{num_runs})\")\n",
    "    print(f\"Average hops: {average_hops:.2f}\" if successful_runs > 0 else \"No successful runs.\")\n",
    "\n",
    "    return success_rate, average_hops\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_PARAMS = {\"max_hops\": 20, \"num_runs\": 20, \"seed\": 42}\n",
    "\n",
    "ml_results = evaluate_pathfinding(G=G, model=model, strategy=\"ml\", max_hops=20, num_runs=20, seed=42, debug=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
